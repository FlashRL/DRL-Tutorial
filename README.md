# DRL-Tutorial

## Related Repos

- [Baseline by OpenAI](https://github.com/openai/baselines)
- [Agnets by Tensorflow](https://github.com/tensorflow/agents)
- [Tianshou by Tsinghua Machine Learning Group](https://github.com/thu-ml/tianshou)

## Useful Tools

- [Papers with Code](https://paperswithcode.com)

## Summarize

|  Algorithm  | Authors     | Publication | Code        | Classification | Features    | Detailed    |
| ----------- | ----------- | ----------- | ----------- | ----------- | ----------- | ----------- |
| Markov Decision Processes (**MDP**) | Puterman, M.L | [John Wiley & Sons 2014](https://books.google.com/books?hl=en-US&lr=&id=VvBjBAAAQBAJ&oi=fnd&pg=PT9&dq=Markov+Decision+Processes&ots=rsmvsLTYSG&sig=GucJYD_6IcYn7obLDce9kSZJWvo&redir_esc=y&gl=US#v=onepage&q=Markov%20Decision%20Processes&f=false) | / | Model | / | TBD | 
| Temporal Difference (**TD**) Learning | Tesauro, G. | [Communications of the ACM 1995](https://dl.acm.org/doi/abs/10.1145/203330.203343) | / | Cornerstone | TBD | TBD |
| Q-Learning | Watkins, C. J. et al. | [Machine Learning 1992](https://link.springer.com/article/10.1007/BF00992698) | / | / | Q Table | TBD |
| Deep Q-Networks (**DQN**) | Mnih, V. et al. | [Nature 2015](https://www.nature.com/articles/nature14236) | [PyTorch](https://github.com/gordicaleksa/pytorch-learn-reinforcement-learning) | Q Networks | Deep network + Q-learning | TBD |
| Deep Deterministic Policy Gradient (**DDPG**) | Lillicrap, T.P. et al. | [arXiv 2015](https://arxiv.org/abs/1509.02971) | TBD | AC | Continuous control | TBD |
| Prioritized Experience Replay (**PER**) | Schaul, T. et al. | [arXiv 2015](https://arxiv.org/abs/1511.05952) | TBD | Replay | TBD | TBD |
| Double DQN | Van Hasselt, H. et al. | [AAAI 2016](https://ojs.aaai.org/index.php/AAAI/article/view/10295) | TBD | Q Networks | TBD | TBD |
| Dueling DQN | Wang, Z. et al. | [ICML 2016](http://proceedings.mlr.press/v48/wangf16.html) | TBD | Q Networks | TBD | TBD |
| Asynchronous Advantage Actor-Critic (**A3C**) | Mnih, V. et al. | [ICML 2016](http://proceedings.mlr.press/v48/mniha16.html?ref=https://githubhelp.com) | TBD | AC | TBD | TBD |
| Hindsight Experience Replay (**HER**) | Andrychowicz, M. et al. | [NeurIPS 2017](https://proceedings.neurips.cc/paper/2017/hash/453fadbd8a1a3af50a9df4df899537b5-Abstract.html) | TBD | Replay | TBD | TBD |
| Proximal Policy Optimization (**PPO**) | Schulman, J. et al. | [arXiv 2017](https://arxiv.org/abs/1707.06347) | TBD | Policy | TBD | TBD |
| Multi-Agent DDPG (**MADDPG**) | Lowe, R. et al. | [NeurIPS 2017](https://proceedings.neurips.cc/paper/2017/hash/68a9750337a418a86fe06c1991a1d64c-Abstract.html) | TBD | MADRL | TBD | TBD |
| Hierarchical Reinforcement Learning (**HRL**) | Vezhnevets, A.S. et al. | [ICML 2017](http://proceedings.mlr.press/v70/vezhnevets17a.html) | TBD | HRL | TBD | TBD |
| Twin Delayed DDPG (**TD3**) | Fujimoto, S. et al. | [ICML 2018](https://proceedings.mlr.press/v80/fujimoto18a.html) | TBD | AC | TBD | TBD |
| Soft Actor-Critic (**SAC**) | Haarnoja, T. et al. | [ICML 2019](https://proceedings.mlr.press/v80/haarnoja18b) | TBD | AC | TBD | TBD |
| ----------- | ----------- | ----------- | TBD | TBD | TBD | TBD |
